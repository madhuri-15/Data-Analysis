{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Store Sales Time Series Analysis","metadata":{}},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport statsmodels.api as sm\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import month_plot, seasonal_plot, plot_acf, plot_pacf, quarter_plot\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\ncolors = ['#126E82', '#0A043C', '#F25287', '#F0A500', '#7D1935']\nplt.style.use('tableau-colorblind10')\nsns.set_style('whitegrid')\nsns.set_palette(colors)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:32.185494Z","iopub.execute_input":"2021-10-19T09:48:32.186254Z","iopub.status.idle":"2021-10-19T09:48:33.960478Z","shell.execute_reply.started":"2021-10-19T09:48:32.186151Z","shell.execute_reply":"2021-10-19T09:48:33.959327Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Loading DataSets","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"../input/store-sales-time-series-forecasting/train.csv\", parse_dates =['date'])\ntest_data = pd.read_csv(\"../input/store-sales-time-series-forecasting/test.csv\", parse_dates =['date'])\nholidays = pd.read_csv(\"../input/store-sales-time-series-forecasting/holidays_events.csv\", parse_dates =['date'])\noil = pd.read_csv(\"../input/store-sales-time-series-forecasting/oil.csv\", parse_dates =['date'])\ntransaction = pd.read_csv(\"../input/store-sales-time-series-forecasting/transactions.csv\", parse_dates =['date'])\nstores = pd.read_csv(\"../input/store-sales-time-series-forecasting/stores.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:33.962228Z","iopub.execute_input":"2021-10-19T09:48:33.962527Z","iopub.status.idle":"2021-10-19T09:48:37.891479Z","shell.execute_reply.started":"2021-10-19T09:48:33.962498Z","shell.execute_reply":"2021-10-19T09:48:37.890650Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# rename the column name of oil dataframe.\noil.rename(columns={'dcoilwtico':'oilPrice'}, inplace=True)\n\n# Let's merge oil data into the train and test data\ntrain = train_data.merge(oil, on='date')\ntest = test_data.merge(oil, on='date') ","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:37.893240Z","iopub.execute_input":"2021-10-19T09:48:37.893588Z","iopub.status.idle":"2021-10-19T09:48:38.194635Z","shell.execute_reply.started":"2021-10-19T09:48:37.893560Z","shell.execute_reply":"2021-10-19T09:48:38.193733Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:38.196773Z","iopub.execute_input":"2021-10-19T09:48:38.197194Z","iopub.status.idle":"2021-10-19T09:48:38.216364Z","shell.execute_reply.started":"2021-10-19T09:48:38.197163Z","shell.execute_reply":"2021-10-19T09:48:38.215801Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:38.217669Z","iopub.execute_input":"2021-10-19T09:48:38.217942Z","iopub.status.idle":"2021-10-19T09:48:38.233328Z","shell.execute_reply.started":"2021-10-19T09:48:38.217913Z","shell.execute_reply":"2021-10-19T09:48:38.232297Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(\"train shape :\", train.shape)\nprint(\"test shape :\", test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:38.235173Z","iopub.execute_input":"2021-10-19T09:48:38.235481Z","iopub.status.idle":"2021-10-19T09:48:38.241274Z","shell.execute_reply.started":"2021-10-19T09:48:38.235441Z","shell.execute_reply":"2021-10-19T09:48:38.240224Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Let's examine holidays dataframe.\nholidays.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:38.242447Z","iopub.execute_input":"2021-10-19T09:48:38.242725Z","iopub.status.idle":"2021-10-19T09:48:38.261614Z","shell.execute_reply.started":"2021-10-19T09:48:38.242678Z","shell.execute_reply":"2021-10-19T09:48:38.261007Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train = train.merge(holidays[['date', 'type', 'transferred']], on='date')\ntrain = train.merge(stores, on='store_nbr')\ntrain.rename(columns={'type_x':'holiday_type', 'type_y':'store_type'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:38.262660Z","iopub.execute_input":"2021-10-19T09:48:38.263040Z","iopub.status.idle":"2021-10-19T09:48:38.428146Z","shell.execute_reply.started":"2021-10-19T09:48:38.263011Z","shell.execute_reply":"2021-10-19T09:48:38.427139Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train['Year'] = train.date.dt.year\ntrain['Year-Month'] = train['date'].apply(lambda x : x.strftime('%Y-%m'))\ntrain['Month'] = train.date.dt.month\ntrain['Day'] = train.date.dt.day","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:38.429449Z","iopub.execute_input":"2021-10-19T09:48:38.429668Z","iopub.status.idle":"2021-10-19T09:48:42.113577Z","shell.execute_reply.started":"2021-10-19T09:48:38.429643Z","shell.execute_reply":"2021-10-19T09:48:42.112782Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Summary Statistics","metadata":{}},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:42.116331Z","iopub.execute_input":"2021-10-19T09:48:42.116564Z","iopub.status.idle":"2021-10-19T09:48:42.288783Z","shell.execute_reply.started":"2021-10-19T09:48:42.116537Z","shell.execute_reply":"2021-10-19T09:48:42.286835Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Missing Values","metadata":{}},{"cell_type":"code","source":"# Missing data in train dataset\ntrain.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:42.290228Z","iopub.execute_input":"2021-10-19T09:48:42.290567Z","iopub.status.idle":"2021-10-19T09:48:42.534387Z","shell.execute_reply.started":"2021-10-19T09:48:42.290525Z","shell.execute_reply":"2021-10-19T09:48:42.533733Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Data Analysis","metadata":{}},{"cell_type":"markdown","source":"### Sales Distribution","metadata":{}},{"cell_type":"code","source":"# box plots to see distribution of sales in each year.\nplt.figure(figsize=(14, 8))\nsns.boxplot(data=train, x='Year', y='sales')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:42.535583Z","iopub.execute_input":"2021-10-19T09:48:42.536421Z","iopub.status.idle":"2021-10-19T09:48:43.014471Z","shell.execute_reply.started":"2021-10-19T09:48:42.536381Z","shell.execute_reply":"2021-10-19T09:48:43.013572Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"We can see that, Outliers present in each year, but specifically in year 2016 there are some extreme outliers present which is becasue of earthquake on April 16, 2016. People rallied in relief efforts donating water and other first need products which greatly affected supermarket sales for several weeks after the earthquake. So, let's remove this extreme outliers in 2016.","metadata":{}},{"cell_type":"code","source":"# Let's examine sales in Year 2016\ndata2016 = train.loc[train.Year == 2016, 'sales']\ndata2016.reset_index(drop=True, inplace=True)\n\n# plot\nplt.figure(figsize=(14, 8))\nplt.scatter(data2016.index, data2016.values)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:43.015977Z","iopub.execute_input":"2021-10-19T09:48:43.016294Z","iopub.status.idle":"2021-10-19T09:48:43.427551Z","shell.execute_reply.started":"2021-10-19T09:48:43.016256Z","shell.execute_reply":"2021-10-19T09:48:43.426096Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# sales greater than 40000\ntrain.loc[train.sales > 40000].shape # there are 10 entries for sales greater than 40,000.\n\n# Let's remove values greater than 40,000.\ntrain = train.loc[train.sales < 40000]\ntrain.sales.max()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:43.428736Z","iopub.execute_input":"2021-10-19T09:48:43.428974Z","iopub.status.idle":"2021-10-19T09:48:43.473935Z","shell.execute_reply.started":"2021-10-19T09:48:43.428947Z","shell.execute_reply":"2021-10-19T09:48:43.473005Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Line plot","metadata":{}},{"cell_type":"code","source":"# Sales observation over time.\nplt.figure(figsize=(14, 8),dpi=100)\nsns.lineplot(data = train, x='date', y='sales', label='Sales')\n\nplt.xlabel('Date')\nplt.ylabel('Sales')\nplt.title(\"Sales observation over time\")\n\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:43.475743Z","iopub.execute_input":"2021-10-19T09:48:43.476089Z","iopub.status.idle":"2021-10-19T09:48:51.132165Z","shell.execute_reply.started":"2021-10-19T09:48:43.476048Z","shell.execute_reply":"2021-10-19T09:48:51.131155Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"There is **increasing** **trend** or **growth** in sales over the time.","metadata":{}},{"cell_type":"code","source":"# Year-to-Year observation of sales.\nyear_data = pd.DataFrame(train.groupby('Year-Month').sum()['sales'])\n\n# plot\nyear_data.plot(kind='line', figsize=(14, 8), marker=\"o\")\n\nplt.xlabel(\"Year-Month\")\nplt.ylabel(\"Sales\")\nplt.title(\"Year-Month observation of Total Sales\")\nplt.plot()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:51.134040Z","iopub.execute_input":"2021-10-19T09:48:51.134356Z","iopub.status.idle":"2021-10-19T09:48:51.537547Z","shell.execute_reply.started":"2021-10-19T09:48:51.134315Z","shell.execute_reply":"2021-10-19T09:48:51.536594Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"We can see that, Every year there is Rise in Sales in Month of December and drop in January. This may be because of Christmas. Let's examine the sales over month and see if the same pattern observe in each year.","metadata":{}},{"cell_type":"code","source":"# Monthly observation of Sales for each year.\nmonthly_sales = pd.DataFrame(train.groupby(by = ['Year', 'Month']).sum()['sales'])\n\n# let's add 0 for remaining months(9, 10, 11, 12) in 2017.\nre_months = [9, 10, 11, 12]\nfor month in re_months:\n    monthly_sales.loc[(2017, month), :] = 0\n    \nyrs = [2013, 2014, 2015, 2016, 2017]\n\n# Plots\nfig, axs = plt.subplots(nrows = 5, ncols=1, figsize=(14, 12))\nfor i in range(len(yrs)):\n    yr = yrs[i]\n    axs[i] = monthly_sales.loc[yr].plot(ax=axs[i], marker=\"o\", label=yr)\n    axs[i].set_ylabel(str(yr)+'Sales')\n\nfig.suptitle(\"Monthly Trend Pattern Observations\")\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:51.539084Z","iopub.execute_input":"2021-10-19T09:48:51.539307Z","iopub.status.idle":"2021-10-19T09:48:52.876477Z","shell.execute_reply.started":"2021-10-19T09:48:51.539280Z","shell.execute_reply":"2021-10-19T09:48:52.875537Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"We can see that, There is peak in December month for each year however, at different levels. <br>\nWages in the public sector are paid every two weeks on the 15th and on the last day of the month. Let's observed the sales at 15th day and last day of month.","metadata":{}},{"cell_type":"code","source":"# prepare data\nfilter1 = (train.Day == 15) \nfilter2 = (train.Day.apply(lambda x: x in [31, 30, 29, 28]))\n\nSales = train.loc[(filter1 | filter2), ['date','Year-Month','sales']]\nsales_data = pd.DataFrame(Sales.groupby(by=['Year-Month']).sum())\n\n#plot\nsales_data.plot(kind='bar', figsize=(14, 8), edgecolor=colors[1], color=colors[-2], fill=True, alpha=0.75, linewidth=1.5)\nsns.lineplot(data = sales_data, x = sales_data.index, y = 'sales', color=colors[1])\n\nplt.title('Monthly Wages Observation')\n\nplt.xticks(rotation=90)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:52.878036Z","iopub.execute_input":"2021-10-19T09:48:52.878336Z","iopub.status.idle":"2021-10-19T09:48:53.522976Z","shell.execute_reply.started":"2021-10-19T09:48:52.878301Z","shell.execute_reply":"2021-10-19T09:48:53.522095Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"We can see that, there is increase in sales in April 2016 as expected.","metadata":{}},{"cell_type":"markdown","source":"### HeatMap","metadata":{}},{"cell_type":"code","source":"# prepare data\nd = train[['date', 'sales']]\nd.set_index('date', inplace=True)\nptable = pd.pivot_table(data=d, index=d.index.year, columns=d.index.quarter)\n\n# plot\nplt.figure(figsize=(14, 8))\nsns.heatmap(ptable, square=True, cmap='Blues', xticklabels=[\"Q1\", \"Q2\", \"Q3\", \"Q4\"])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:53.524059Z","iopub.execute_input":"2021-10-19T09:48:53.524276Z","iopub.status.idle":"2021-10-19T09:48:54.428986Z","shell.execute_reply.started":"2021-10-19T09:48:53.524252Z","shell.execute_reply":"2021-10-19T09:48:54.428160Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Heatmap shows peak at Quarter Q4 for every year. For each of the years the upward trend observed in all quarters.","metadata":{}},{"cell_type":"markdown","source":"## Seasonality Factor","metadata":{}},{"cell_type":"code","source":"# Groupby Sales by Quarter\n# Only use upto 2016 because we have partial data for 2017\ndata_2016 = d.loc[:'2016']\navg_2016 = np.int(data_2016.mean())\n\n# Avg sales per quarter\nqrt_avg = data_2016.groupby(data_2016.index.quarter)[\"sales\"].mean()\n\n# Groupby quarter\nqrt_table = pd.pivot_table(data_2016, index=data_2016.index.quarter, columns=data_2016.index.year)\n\n# add qrt_avg to qrt_table\nqrt_table[\"avg\"] = qrt_avg\n\n# Additive Seasonality Factor: Subtract mean from avg column\nqrt_table[\"additive\"] = (qrt_table[\"avg\"] - avg_2016).round(2)\n\n# Multiplicative Seasonality Factor: Divide mean from avg column\nqrt_table[\"multiplicative\"] = (qrt_table[\"avg\"]/avg_2016).round(2)\n\nqrt_table.index.name=\"Quarters\"\nprint(\"Seasonal Factor Analysis Table\")\nqrt_table","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:54.430628Z","iopub.execute_input":"2021-10-19T09:48:54.430995Z","iopub.status.idle":"2021-10-19T09:48:55.040089Z","shell.execute_reply.started":"2021-10-19T09:48:54.430955Z","shell.execute_reply":"2021-10-19T09:48:55.039135Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Seasonality Analysis table shows that in quarter 4 we can see that there is increament in sales by ~69k as compare to others and there is sudden drop in quarter 1. We can see from the above table is that the sales is not stable, The multiplicative seasonallity would capture the pattern better than additive seasonality.","metadata":{}},{"cell_type":"markdown","source":"## Stationarity\nTime series is Stationary if it has,\n* Constant Mean\n* Constant Variance\n* Constant Covariance\n\nLet's verify it by observing change in mean, variance and statistical test (**adfuller**)","metadata":{}},{"cell_type":"code","source":"# prepare_data \ndata = pd.DataFrame(train_data.groupby(by=['date']).sum()['sales'])\n\ndef test_stationarity(timeseries, title):\n    \n    # calculating rolling statistics.\n    roll_mean = timeseries['sales'].rolling(window = 91,  center=True).mean()\n    roll_std = timeseries['sales'].rolling(window = 91,  center=True).std()\n\n    # plotting rolling statistics with orignal data.\n    plt.figure(figsize=(12, 4), dpi=100)\n    plt.plot(timeseries.sales, label= title, marker=\".\", alpha=0.6)\n    plt.plot(roll_mean, label=\"Rolling Mean\", color=\"red\", linestyle=\"--\")\n    plt.plot(roll_std, label=\"Rolling Standard Deviation\")\n\n    plt.title(\"Rolling Statistics\")\n    plt.legend()\n    plt.show()\n\ntest_stationarity(data, 'raw data')","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:55.041691Z","iopub.execute_input":"2021-10-19T09:48:55.041953Z","iopub.status.idle":"2021-10-19T09:48:55.627552Z","shell.execute_reply.started":"2021-10-19T09:48:55.041925Z","shell.execute_reply":"2021-10-19T09:48:55.626805Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"Above plot show that, Both Mean and Standard deviation is increasing over time. Therefore, this time series is not stationary.","metadata":{}},{"cell_type":"markdown","source":"### Coefficient of Variance\nC.V = std/mean\n\n* If C.V<0.75 **-** Low Variability\n* If 0.75<C.V<1.3 **-** Medium Variability\n* If C.V>1.3 **-** High Variability","metadata":{}},{"cell_type":"code","source":"# coefficient of variance. \ncv = data.sales.std()/data.sales.mean()\ncv","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:55.628797Z","iopub.execute_input":"2021-10-19T09:48:55.629262Z","iopub.status.idle":"2021-10-19T09:48:55.647367Z","shell.execute_reply.started":"2021-10-19T09:48:55.629223Z","shell.execute_reply":"2021-10-19T09:48:55.646705Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"This has low variability process.","metadata":{}},{"cell_type":"code","source":"# Let's find if covariance is constant or not using acf plot and pacf plot of statsmodels.\nplt.rcParams['figure.figsize'] = (14, 4);\nplot_acf(data.sales);\nplt.tight_layout()\nplot_pacf(data.sales);\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:55.648697Z","iopub.execute_input":"2021-10-19T09:48:55.649663Z","iopub.status.idle":"2021-10-19T09:48:56.510613Z","shell.execute_reply.started":"2021-10-19T09:48:55.649618Z","shell.execute_reply":"2021-10-19T09:48:56.509723Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"The ACF Plot shows that, it has momentum process since all AC's are positive. Let's check stationarity of data using Augmented Dickey-fuller test (adfuller test).","metadata":{}},{"cell_type":"markdown","source":"### ADFuller Test.","metadata":{}},{"cell_type":"code","source":"# Let's take a adfuller test on sales data.\n\ndef adfuller_test(data, description):\n    \n    print(f\"Augmented Dickey-fuller test result for {description}\")\n    result = adfuller(data.dropna(), autolag=\"AIC\")\n    \n    print(\"ADF test statistic: {:.3f}\".format(result[0]))\n    print(\"p-value:{:.3f}\".format(result[1]))\n    \n    print(\"Critical Values:\")\n    for k, v in result[4].items():\n        print('\\t{}: {} - The data is {} stationary with {}% confidence'.format(k, v, 'not' if v<result[0] else '', 100-int(k[:-1])))\n        \nadfuller_test(data, 'raw data')","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:56.511877Z","iopub.execute_input":"2021-10-19T09:48:56.512098Z","iopub.status.idle":"2021-10-19T09:48:56.604210Z","shell.execute_reply.started":"2021-10-19T09:48:56.512072Z","shell.execute_reply":"2021-10-19T09:48:56.603335Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"Augmented Dickey-fuller test is a statistical test for stationarity. If the p-value is less than 0.05 then the series is not stationary. Here the p-value is ~0.08989 so, the time series is not stationary.","metadata":{}},{"cell_type":"markdown","source":"# To make Time Series Stationary\n## Detrend","metadata":{}},{"cell_type":"code","source":"# de-trending\ndata_detrend = ((data - data.rolling(91).mean()) / data.rolling(91).std()).dropna()\n\n# To check if detrended data is stationary or not?\nadfuller_test(data_detrend, \"de-trended data\")\ntest_stationarity(data_detrend, \"de-trended data\")","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:56.605740Z","iopub.execute_input":"2021-10-19T09:48:56.606245Z","iopub.status.idle":"2021-10-19T09:48:57.294607Z","shell.execute_reply.started":"2021-10-19T09:48:56.606204Z","shell.execute_reply":"2021-10-19T09:48:57.293799Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"Both the adfuller statistical test and rolling statistics graph shows that the series is now stationary. The relative smoothness of rolling mean and rolling standard deviation graph shows the sationarity in time series.","metadata":{}},{"cell_type":"markdown","source":"## Differencing","metadata":{}},{"cell_type":"markdown","source":"This method removes the underlying seasonal or cyclical patterns in the time series. I used a 15-lag difference since wages in public sector is paid every 2 weeks.","metadata":{}},{"cell_type":"code","source":"diff_data = (data - data.shift(15))\ntest_stationarity(diff_data, 'difference data')\nadfuller_test(diff_data, 'difference data')","metadata":{"execution":{"iopub.status.busy":"2021-10-19T09:48:57.295866Z","iopub.execute_input":"2021-10-19T09:48:57.296691Z","iopub.status.idle":"2021-10-19T09:48:57.751868Z","shell.execute_reply.started":"2021-10-19T09:48:57.296646Z","shell.execute_reply":"2021-10-19T09:48:57.750946Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"Both stationarity tests shows that, the this time series is stationary. Differencing performs much better as compare to de-trending.","metadata":{}}]}